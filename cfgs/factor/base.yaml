
should_use: false
num_factors: 4
encoder:
  dim:
    low: 256
    high: 512

told:
  attention_network:
    num_factors: ${factor.num_factors}
    in_features: ${latent_dim}
    attention_cfg:
      mlp:
        should_use: True
        hidden_features: ${latent_dim}
        num_layers: 2
      input: concat_factors
  dynamics_model:
    action_dim: ${action_dim}
    input_dim: ${latent_dim}
    hidden_dim: 128
    num_objects: ${factor.num_factors}
    ignore_action: False
    copy_action: True
    are_actions_discrete: False
  loss:
    hinge: 1.0
    sigma: 0.5
    contrastive_coef: 1.0